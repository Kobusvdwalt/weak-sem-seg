
#
# Perfect Classification Scores = No Gradients To Visualize From 
#

Ran into an interesting problem with GradCAM and GradCAM++ where the resulting visualizations were empty.
After some investigation I realized that the classifier was predicting the class with 100% probability.
This means there is no error, and thus no gradient to backpropegate. The solution to this was to use
a linear activation function instead of Sigmoid on the last layer. Theoretically the sigmoid should never have
a zero gradient since the output tends to 1 but never reaches it. In reality however the computer runs out
of precision and one ends up with the classic vanishing gradient.
----


#
# Preprocess your data !!!!!
#

Realized that since we are using a pretrained classifier the feature detectors might be underperforming because
we are not preprocessing the data in the same fashion.

Will now normilze the input, hopefully we get better results.
Edit: Yes. We saw an increase in accuracy. From ~11.5/20 to 12.3/20

Next steps is to train with rotation augmentation and gaus noise
After that we measure CAM, GradCAM and GradCAM++


# Binary classification validation eval results :
* Unbalanced training
* Label smoothing 0.1 and 0.9
(pytorch) pjvanderwalt@mscluster0:~/weakly-supervised-segmentation/classification_binary$ python eval-measure.py
aeroplane 0.9355436236850547
bicycle 0.848836698036824
bird 0.911678076537396
boat 0.8239331304642684
bottle 0.559764080808165
bus 0.9067273826152092
car 0.8387856006822789
cat 0.9309431681899206
chair 0.6775765766916373
cow 0.7116764505908987
diningtable 0.6265109078412254
dog 0.8690029644045673
horse 0.8636836789726292
motorbike 0.87571379642926
person 0.9571809351105647
pottedplant 0.6194925380887766
sheep 0.8066649598872339
sofa 0.6272293214933369
train 0.9413914705912546
tvmonitor 0.8442273120026439
mean 0.8088281336561571


# Multiclass classification validation eval results :
* Label smoothing 0.1 and 0.9
(pytorch) pjvanderwalt@mscluster0:~/weakly-supervised-segmentation/classification_multiclass$ python eval-measure.py
aeroplane 0.9559671869056128
bicycle 0.8505393275801546
bird 0.9191668305823788
boat 0.8554488165810482
bottle 0.5952792570128366
bus 0.9255318012177642
car 0.8423198381115727
cat 0.9310126221695163
chair 0.7197382341054036
cow 0.7538465025926167
diningtable 0.6559150789216615
dog 0.897996337196206
horse 0.8791299614911887
motorbike 0.8753179886689594
person 0.9541123923599463
pottedplant 0.6086534089611444
sheep 0.8235042216024152
sofa 0.6751539104206469
train 0.9410000845332425
tvmonitor 0.8446981696860653
mean 0.825216598535019

# Binary classification validation eval results :
* Balanced Training
* Label smoothing 0.1 and 0.9
(pytorch) pjvanderwalt@mscluster0:~/weakly-supervised-segmentation/classification_binary$ python eval-measure.py
aeroplane 0.9535405475017039
bicycle 0.8668459553905974
bird 0.9172357634828642
boat 0.8394793865466611
bottle 0.5653628250330727
bus 0.9183368858651229
car 0.8278017595976266
cat 0.9325504522610174
chair 0.6818404808291929
cow 0.7407849606740569
diningtable 0.6486914868017724
dog 0.8694148004776614
horse 0.8709079233591818
motorbike 0.8905213171709813
person 0.9579015924447263
pottedplant 0.618923059889053
sheep 0.8235173985837537
sofa 0.682884978230588
train 0.94928806583001
tvmonitor 0.8526499183804621
mean 0.8204239779175051

Multicalss :  mean 0.825216598535019    Visualization : ?
Binary :      mean 0.820423977917505    Visualization : ?

TODO:
* Measure the correlation between accuracy and visualiztion score
* Measure the visualization
* Train multiple network architectures
* Add dilated convolution

Thought: 
* Instead of doing dilated convolution we can use different levels of training to capture less descriminative
  but more encapsulating visualizations


  0.0000 0.3033 0.1876 0.0000 0.0463 0.3157 0.0000 0.0000 0.0000 0.0239 0.0000 0.0000 0.0000 0.1929 0.0000 0.2697 0.0000 0.1854 0.0504 0.3319 0.1938
  0.0000 0.2370 0.1744 0.0000 0.0490 0.2279 0.0000 0.0000 0.0000 0.0087 0.0000 0.0000 0.0000 0.1259 0.0000 0.4390 0.0000 0.2100 0.0887 0.2515 0.1941 

TODO: 
+ Run multiclass eval on test set
>! Upload to VOC evaluation server

+ Run multiclass eval
+ Run multiclass eval-measure
> Run binary eval
- Run binary eval-measure
- Compare binary to multiclass

+ Train upscale net
> Run upscale eval 
- Run upscale eval-measure
- Compare upscale to normal

Multiclass visualization :
[0.79761261 0.24486322 0.08994405 0.25607232 0.14638556 0.10756468
 0.34122748 0.22186226 0.32054052 0.10405003 0.16237428 0.06636935
 0.30283547 0.26581762 0.34022624 0.2507742  0.10339055 0.30953206
 0.11021163 0.32589207 0.25191961]
0.2160926602699448

Multiclass Using labels :
[0.80109099 0.29063062 0.12605975 0.28521222 0.20350497 0.20370228
 0.42147236 0.27893014 0.40439701 0.16428382 0.34031239 0.15343174
 0.36611207 0.35262763 0.41620707 0.28292502 0.18433337 0.36126045
 0.24673307 0.36076103 0.32018538]
0.2881541195965619

Upsacle visualization :
[0.79191846 0.25779909 0.08049098 0.23121353 0.11958069 0.08926786
 0.25593503 0.18464253 0.30921459 0.08731919 0.20290067 0.10623617
 0.31148813 0.26842028 0.30507434 0.21135122 0.1050026  0.30807601
 0.10259893 0.21150782 0.21784749]
0.19829835750157215

Upsacle using labels:
[0.79656485 0.29455195 0.1201169  0.28426962 0.1757746  0.17546934
 0.38132861 0.25054155 0.3893495  0.15546594 0.37543719 0.20484208
 0.35762508 0.33837889 0.38229607 0.25041258 0.16573126 0.37186416
 0.23676928 0.26801218 0.30781656]
0.2743026664130116

Binary visualization :
